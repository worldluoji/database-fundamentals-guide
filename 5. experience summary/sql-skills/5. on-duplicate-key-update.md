# ON DUPLICATE KEY UPDATE

-- 创建用户表
```sql
CREATE TABLE users (
    id INT PRIMARY KEY COMMENT '用户ID',
    name VARCHAR(50) COMMENT '用户名',
    email VARCHAR(100) COMMENT '邮箱'
) ENGINE=InnoDB CHARSET=utf8mb4  COMMENT='用户信息表';
```

-- 使用 ON DUPLICATE KEY UPDATE 实现插入或更新
```sql
INSERT INTO users (id, name, email) 
VALUES 
(1, '张三', 'zhangsan_new@example.com'),
(4, '赵六', 'zhaoliu_new@example.com')
ON DUPLICATE KEY UPDATE 
    name = VALUES(name),
    email = VALUES(email);
```
如果用户已存在就更新，不存在就插入，一行代码搞定！


---

## 为什么使用 ON DUPLICATE KEY UPDATE 代替REPLACE INTO

MySQL 中 `REPLACE INTO` 导致的死锁问题是一个常见的痛点，尤其是在高并发或批量操作的场景下。这是因为 `REPLACE INTO` 的底层机制并非原子操作，而是在存在唯一键冲突时，先执行 `DELETE` 再执行 `INSERT`。这个过程会涉及多种锁（共享锁、排他锁、间隙锁、插入意向锁），在并发环境下多个事务相互等待对方持有的锁资源就容易形成死锁。

**为什么批量 `REPLACE INTO` 容易导致死锁？**

1.  **锁升级过程：**
    *   当发现唯一键冲突时，`REPLACE INTO` 需要获取该记录的 `S` 锁（共享锁，用于检查冲突）。
    *   确定需要 `DELETE` 该记录时，必须将 `S` 锁升级为 `X` 锁（排他锁）。
    *   `DELETE` 操作本身需要 `X` 锁。
    *   后续的 `INSERT` 操作需要获取插入位置的意向插入锁 (`INSERT INTENTION LOCK`) 以及新记录的 `X` 锁。
2.  **批量操作增加锁范围：** 一次性处理多条记录，意味着一个事务可能同时持有或试图获取大量记录的锁，增加了与其他事务请求锁的顺序冲突的可能性。
3.  **并发事务交错：** 两个或更多事务可能同时处理相同或相邻索引范围（尤其是唯一索引）的记录。当它们请求锁的顺序不一致时（例如，事务A锁了记录1，尝试锁记录2；事务B锁了记录2，尝试锁记录1），就容易形成死锁环 (`AB-BA`)。间隙锁的存在会锁定索引区间，使得问题更复杂。
4.  **`INSERT INTENTION LOCK` 冲突：** 多个事务试图在同一个索引间隙插入新记录时，它们请求的 `INSERT INTENTION LOCK` 之间会互相阻塞，也容易参与死锁环。

**解决方案与规避策略：**

1.  **优先使用 `INSERT ... ON DUPLICATE KEY UPDATE` (DUPLICATE KEY UPDATE)：**
    *   **这是最推荐、最根本的解决方案。**
    *   **为什么有效：** 当发现唯一键冲突时，`DUPLICATE KEY UPDATE` 不会删除旧行再插入新行，而是直接在现有的行上更新指定的列。这个过程只需要在冲突时对该行加 `X` 锁，避免了 `DELETE` 操作和相关的 `INSERT` 操作。
    *   **优点：** 大大简化了锁操作（只有SELECT的锁和UPDATE的锁），显著降低死锁概率；避免不必要的 `AUTO_INCREMENT` 值浪费；**性能通常更好**。
    *   **语法示例：**
        ```sql
        INSERT INTO your_table (id, col1, col2, ...) VALUES (value1, value2, ...), (value3, value4, ...), ... 
        ON DUPLICATE KEY UPDATE 
            col1 = VALUES(col1), 
            col2 = VALUES(col2), 
            ...;
        ```
        *   批量插入时替换为多条 `VALUES(...)`。
        *   明确列出需要更新的列 (`col1 = VALUES(col1)`)，避免意外更新非意图列（如主键或不想更新的列）。

2.  **改用 `UPDATE + INSERT` (先查后插) 策略：**
    *   **手动实现：**
        *   先将需要插入/更新的数据批量加载到一个临时表或内存结构中。
        *   使用单个查询`SELECT ... FROM temp_table t LEFT JOIN your_table y ON t.unique_key = y.unique_key WHERE y.unique_key IS NOT NULL`找出需要更新的记录。
        *   使用单个`UPDATE your_table JOIN temp_table ... SET ...`语句批量更新这些记录。
        *   使用单个查询`SELECT ... FROM temp_table t LEFT JOIN your_table y ON t.unique_key = y.unique_key WHERE y.unique_key IS NULL`找出需要插入的记录。
        *   使用单个`INSERT INTO your_table SELECT ... FROM temp_table WHERE ...`语句批量插入这些记录。
    *   **应用程序逻辑实现 (业务层控制)：** 在应用层逻辑中，对每一条数据：
        *   尝试 `SELECT ... FOR UPDATE` 查询目标记录（加 `X` 锁）。
        *   如果找到记录，则执行 `UPDATE`。
        *   如果未找到记录，则执行 `INSERT`。
        *   **注意：** 批量操作时，这种方法效率较低，且务必**严格按照相同顺序（如按唯一键排序）加锁**所有记录，以避免死锁。对每一条记录操作后立即提交事务（小事务）也能降低风险，但牺牲了批量操作的原子性优势。

3.  **拆分批量操作为更小的批次：**
    *   将一次处理大量记录的 `REPLACE INTO` 拆分成多次处理较小批次的操作（例如每次处理100条）。
    *   **优点：** 每个事务持有锁的时间变短、涉及的记录变少，死锁发生的概率降低。即使发生死锁，影响范围也较小。
    *   **缺点：** 会增加事务提交的次数，可能略微降低整体吞吐量（虽然每个事务更快了）。需要在吞吐量和死锁风险之间权衡。

4.  **调整事务隔离级别（谨慎使用）：**
    *   默认的 `REPEATABLE READ` 隔离级别会使用间隙锁来防止幻读，这增加了死锁的可能性。
    *   将事务隔离级别降低为 `READ COMMITTED`。在这个级别下，InnoDB 通常不持有间隙锁（除非使用了 `FOR UPDATE` 或 `LOCK IN SHARE MODE` 等显示加锁语句），从而减少了锁冲突的可能性。
    *   **重要警告：**
        *   `READ COMMITTED` 允许幻读和非可重复读。确保你的业务逻辑能容忍这些现象。
        *   只修改那些确实需要降低隔离级别来解决死锁问题的特定事务或连接。不要盲目全局修改。
        *   设置方法：在事务开始时执行 `SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;`。
        *   使用 `READ COMMITTED` 后，`INSERT ... ON DUPLICATE KEY UPDATE` 仍是更好的选择，因为它本身的锁需求就更少。

5.  **减少唯一键冲突：**
    *   **业务设计：** 尽量减少不同事务同时修改 *相同* 唯一键记录的概率（热点更新问题）。可以通过业务逻辑设计（如数据分片、减少操作粒度）来缓解。
    *   **操作排序：** 如果应用程序逻辑允许，**确保所有需要操作相同表/索引的操作（无论使用哪种语句）都按照相同顺序访问记录（例如总是按主键升序访问）**。这可以避免 `AB-BA` 类型的经典死锁。将 `REPLACE INTO` 的数据预先按主键或唯一键排序后再执行。

6.  **分析死锁日志：**
    *   当发生死锁时，务必查看 `SHOW ENGINE INNODB STATUS;` 输出的 `LATEST DETECTED DEADLOCK` 部分。
    *   **关键信息：**
        *   `*** (1) TRANSACTION:` 和 `*** (2) TRANSACTION:`：死锁涉及的两个事务。
        *   `TRANSACTION HOLDS THE LOCK(S):`：每个事务当前持有的锁（类型、锁定的对象）。
        *   `TRANSACTION WAITING FOR THIS LOCK TO BE GRANTED:`：每个事务在等待什么锁（类型、锁定的对象）。
        *   `WE ROLL BACK TRANSACTION (1)/(2)`：InnoDB 选择回滚的事务。
    *   分析这些信息能够**精确定位**死锁的根本原因：具体是哪些语句、哪些锁冲突（记录锁还是间隙锁？）、在哪些索引上冲突。这对于选择最合适的解决方案至关重要（例如，看到大量间隙锁冲突，选择`READ COMMITTED`或调整索引；看到`DELETE/INSERT`冲突则选择`INSERT ... ON DUPLICATE KEY UPDATE`）。

**总结与推荐：**

*   **首选方案： 彻底将 `REPLACE INTO` 替换为 `INSERT ... ON DUPLICATE KEY UPDATE`**。这是避免由 `DELETE-then-INSERT` 机制引发死锁的最有效、最推荐、通常也是性能最佳的方法。
*   **强力次选方案： 实现 `UPDATE + INSERT` 逻辑**。在无法使用 `DUPLICATE KEY UPDATE` 的场景下（例如有复杂约束或版本要求），手动控制锁的顺序和范围。
*   **缓解性策略：** 结合使用**拆分小批次**操作和**保持操作顺序一致**。这有助于降低死锁概率。
*   **谨慎调整：** 在理解风险的前提下，对特定连接/事务调整隔离级别为 `READ COMMITTED`。**务必先分析死锁日志**。
*   **根因分析：** **务必**在发生死锁后检查 `SHOW ENGINE INNODB STATUS;` 的输出，了解具体的锁冲突细节，指导后续优化。

**综合来看，`INSERT ... ON DUPLICATE KEY UPDATE` 应该是处理需要“存在即更新，否则插入”逻辑的首选方案，它能最有效地避免 `REPLACE INTO` 固有的死锁陷阱。** 只有在特定限制下，才考虑其他方案。同时，结合业务逻辑优化和适当的事务控制，可以进一步减少死锁发生的可能性。